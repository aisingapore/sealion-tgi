services:
  llama3-8b-cpt-sea-lionv2.1-instruct-tgi:
    image: ghcr.io/huggingface/text-generation-inference:2.2.0
    container_name: llama3-8b-cpt-sea-lionv2.1-instruct-tgi
    ports:
      - "8000:80"
    restart: unless-stopped
    volumes:
      - tgi-data:/data
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    command: [
      "--json-output",
      "--quantize", "bitsandbytes-nf4",
      "--max-input-tokens", "256",
      "--max-batch-prefill-tokens", "512",
      "--model-id", "aisingapore/llama3-8b-cpt-sea-lionv2.1-instruct"
    ]

volumes:
  tgi-data:
